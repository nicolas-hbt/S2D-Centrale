{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implémentation de méthodes élémentaires pour la classification supervisée : ADL, ADQ, NB et $k$-NN \n",
    "\n",
    "\n",
    "### *Adrien BERSIER, Thomas FRIEDLAND, Nicolas HUBERT*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de données [Vertebral Column](https://archive.ics.uci.edu/ml/datasets/Vertebral+Column) permet d'étudier les pathologies d'hernie discale et de Spondylolisthesis. Ces deux pathologies sont regroupées dans le jeu de données en une seule seule catégorie dite `Abnormale`. \n",
    "\n",
    "Il s'agit donc d'un problème de classification supervisée à deux classes :\n",
    "- Normale (NO) \n",
    "- Abnormale (AB)    \n",
    "\n",
    "avec 6 variables bio-mécaniques disponibles (features).\n",
    "\n",
    "L'objectif du TP est d'implémenter quelques méthodes simples de classification supervisée pour ce problème.\n",
    "\n",
    "Les données sont disponibles dans le fichier `column_2C.dat`  : lien [Data Folder](https://archive.ics.uci.edu/ml/machine-learning-databases/00212/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.covariance import empirical_covariance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Importation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Télécharger le fichier column_2C.dat depuis le site de l'UCI : https://archive.ics.uci.edu/ml/datasets/Vertebral+Column#, par exemple avec la librairie [pandas](https://pandas.pydata.org/pandas-docs/stable/10min.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path= \"C:/Users/acer/Documents/GitHub/Centrale-S2D/vertebral_column_data/column_2C.dat\"\n",
    "Vertebral = pd.read_table(file_path,\n",
    "                          delim_whitespace=True\n",
    "                         )\n",
    "Vertebral.columns = [\"pelvic_incidence\",\n",
    "                                       \"pelvic_tilt\",\n",
    "                                       \"lumbar_lordosis_angle\",\n",
    "                                       \"sacral_slope\",\n",
    "                                       \"pelvic_radius\",\n",
    "                                       \"degree_spondylolisthesis\",\n",
    "                                       \"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Vérifier à l'aide des méthodes `.head()`  et `describe()` que les données sont bien importées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pelvic_incidence</th>\n",
       "      <th>pelvic_tilt</th>\n",
       "      <th>lumbar_lordosis_angle</th>\n",
       "      <th>sacral_slope</th>\n",
       "      <th>pelvic_radius</th>\n",
       "      <th>degree_spondylolisthesis</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.06</td>\n",
       "      <td>10.06</td>\n",
       "      <td>25.02</td>\n",
       "      <td>29.00</td>\n",
       "      <td>114.41</td>\n",
       "      <td>4.56</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68.83</td>\n",
       "      <td>22.22</td>\n",
       "      <td>50.09</td>\n",
       "      <td>46.61</td>\n",
       "      <td>105.99</td>\n",
       "      <td>-3.53</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.30</td>\n",
       "      <td>24.65</td>\n",
       "      <td>44.31</td>\n",
       "      <td>44.64</td>\n",
       "      <td>101.87</td>\n",
       "      <td>11.21</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.71</td>\n",
       "      <td>9.65</td>\n",
       "      <td>28.32</td>\n",
       "      <td>40.06</td>\n",
       "      <td>108.17</td>\n",
       "      <td>7.92</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.25</td>\n",
       "      <td>13.92</td>\n",
       "      <td>25.12</td>\n",
       "      <td>26.33</td>\n",
       "      <td>130.33</td>\n",
       "      <td>2.23</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pelvic_incidence  pelvic_tilt  lumbar_lordosis_angle  sacral_slope  \\\n",
       "0             39.06        10.06                  25.02         29.00   \n",
       "1             68.83        22.22                  50.09         46.61   \n",
       "2             69.30        24.65                  44.31         44.64   \n",
       "3             49.71         9.65                  28.32         40.06   \n",
       "4             40.25        13.92                  25.12         26.33   \n",
       "\n",
       "   pelvic_radius  degree_spondylolisthesis class  \n",
       "0         114.41                      4.56    AB  \n",
       "1         105.99                     -3.53    AB  \n",
       "2         101.87                     11.21    AB  \n",
       "3         108.17                      7.92    AB  \n",
       "4         130.33                      2.23    AB  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vertebral.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pelvic_incidence</th>\n",
       "      <th>pelvic_tilt</th>\n",
       "      <th>lumbar_lordosis_angle</th>\n",
       "      <th>sacral_slope</th>\n",
       "      <th>pelvic_radius</th>\n",
       "      <th>degree_spondylolisthesis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>309.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>309.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60.488285</td>\n",
       "      <td>17.526699</td>\n",
       "      <td>51.970583</td>\n",
       "      <td>42.961877</td>\n",
       "      <td>117.982848</td>\n",
       "      <td>26.382654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.263462</td>\n",
       "      <td>10.020300</td>\n",
       "      <td>18.570553</td>\n",
       "      <td>13.443779</td>\n",
       "      <td>13.293909</td>\n",
       "      <td>37.589284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>26.150000</td>\n",
       "      <td>-6.550000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>70.080000</td>\n",
       "      <td>-11.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>46.430000</td>\n",
       "      <td>10.660000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>33.340000</td>\n",
       "      <td>110.710000</td>\n",
       "      <td>1.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>58.600000</td>\n",
       "      <td>16.300000</td>\n",
       "      <td>49.780000</td>\n",
       "      <td>42.440000</td>\n",
       "      <td>118.340000</td>\n",
       "      <td>12.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>72.960000</td>\n",
       "      <td>21.940000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>52.740000</td>\n",
       "      <td>125.480000</td>\n",
       "      <td>41.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>129.830000</td>\n",
       "      <td>49.430000</td>\n",
       "      <td>125.740000</td>\n",
       "      <td>121.430000</td>\n",
       "      <td>163.070000</td>\n",
       "      <td>418.540000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pelvic_incidence  pelvic_tilt  lumbar_lordosis_angle  sacral_slope  \\\n",
       "count        309.000000   309.000000             309.000000    309.000000   \n",
       "mean          60.488285    17.526699              51.970583     42.961877   \n",
       "std           17.263462    10.020300              18.570553     13.443779   \n",
       "min           26.150000    -6.550000              14.000000     13.370000   \n",
       "25%           46.430000    10.660000              37.000000     33.340000   \n",
       "50%           58.600000    16.300000              49.780000     42.440000   \n",
       "75%           72.960000    21.940000              63.000000     52.740000   \n",
       "max          129.830000    49.430000             125.740000    121.430000   \n",
       "\n",
       "       pelvic_radius  degree_spondylolisthesis  \n",
       "count     309.000000                309.000000  \n",
       "mean      117.982848                 26.382654  \n",
       "std        13.293909                 37.589284  \n",
       "min        70.080000                -11.060000  \n",
       "25%       110.710000                  1.630000  \n",
       "50%       118.340000                 12.070000  \n",
       "75%       125.480000                 41.420000  \n",
       "max       163.070000                418.540000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vertebral.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Les librairies de ML telles que `sckitlearn` prennent en entrée des tableau numpy (pas du pandas). Créer un tableau numpy pour les features et une liste pour les classes : que vous nommerez `VertebralVar`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VertebralVar_pandas = Vertebral.iloc[:,0:6] # ne prend pas la 6ème colonne\n",
    "# extraction de colonnes en pandas\n",
    "# puis conversion en tableau numpy :\n",
    "VertebralVar  = VertebralVar_pandas.values # X observés\n",
    "VertebralClas = Vertebral.iloc[:,6].values # Y observé (dernière colonne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Découpage train / test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> En utilisant la fonction [`train_test_split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) de la librairie [`sklearn.model_selection`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection), sélectionner aléatoirement 200 observations pour l'échantillon d'apprentissage et garder le reste pour l'échantillon de validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "VertebralVar_train,VertebralVar_test,VertebralClas_train, VertebralClas_test = train_test_split(VertebralVar,\n",
    "                                                                                                VertebralClas, \n",
    "                                                                                                train_size=200, random_state=0)\n",
    "ntot=VertebralClas.shape[0]\n",
    "ntrain=VertebralVar_train.shape[0]\n",
    "ntest=ntot-ntrain\n",
    "ntrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 50.91,  23.02,  47.  ,  27.9 , 117.42,  -2.53],\n",
       "       [ 35.88,   1.11,  43.46,  34.77, 126.92,  -1.63],\n",
       "       [ 68.83,  22.22,  50.09,  46.61, 105.99,  -3.53],\n",
       "       ...,\n",
       "       [ 65.54,  24.16,  45.78,  41.38, 136.44,  16.38],\n",
       "       [ 40.56,  17.98,  34.  ,  22.58, 121.05,  -1.54],\n",
       "       [ 50.83,   9.06,  56.3 ,  41.76,  79.  ,  23.04]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VertebralVar_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AB', 'NO', 'AB', 'NO', 'AB', 'AB', 'NO', 'AB', 'AB', 'AB', 'AB',\n",
       "       'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'NO', 'NO', 'NO', 'AB', 'AB',\n",
       "       'AB', 'NO', 'AB', 'NO', 'NO', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB',\n",
       "       'AB', 'AB', 'AB', 'NO', 'AB', 'AB', 'NO', 'NO', 'NO', 'NO', 'AB',\n",
       "       'NO', 'AB', 'AB', 'NO', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'NO',\n",
       "       'NO', 'AB', 'NO', 'NO', 'NO', 'AB', 'AB', 'AB', 'NO', 'AB', 'NO',\n",
       "       'AB', 'AB', 'NO', 'AB', 'AB', 'AB', 'AB', 'AB', 'NO', 'NO', 'NO',\n",
       "       'AB', 'NO', 'AB', 'AB', 'NO', 'AB', 'AB', 'NO', 'AB', 'NO', 'AB',\n",
       "       'AB', 'AB', 'NO', 'NO', 'AB', 'AB', 'AB', 'NO', 'AB', 'NO', 'AB',\n",
       "       'NO', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'NO', 'AB', 'NO', 'NO',\n",
       "       'AB', 'AB', 'AB', 'AB', 'AB', 'NO', 'AB', 'AB', 'AB', 'AB', 'NO',\n",
       "       'AB', 'AB', 'AB', 'NO', 'AB', 'AB', 'AB', 'AB', 'NO', 'NO', 'AB',\n",
       "       'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'NO', 'NO', 'AB', 'NO',\n",
       "       'AB', 'AB', 'NO', 'AB', 'AB', 'AB', 'NO', 'NO', 'AB', 'AB', 'NO',\n",
       "       'AB', 'AB', 'NO', 'AB', 'AB', 'AB', 'AB', 'AB', 'NO', 'AB', 'AB',\n",
       "       'AB', 'AB', 'AB', 'NO', 'NO', 'AB', 'NO', 'AB', 'AB', 'AB', 'NO',\n",
       "       'AB', 'NO', 'AB', 'AB', 'AB', 'NO', 'AB', 'NO', 'AB', 'AB', 'AB',\n",
       "       'AB', 'AB', 'NO', 'NO', 'NO', 'NO', 'AB', 'AB', 'NO', 'AB', 'AB',\n",
       "       'AB', 'AB'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VertebralClas_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque : on peut aussi le faire à la main avec la fonction [`sklearn.utils.shuffle`](https://scikit-learn.org/stable/modules/generated/sklearn.utils.shuffle.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction des deux classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Extraire les deux sous échantillons Abnormale et Normale pour les données d'apprentissage et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.0910e+01  2.3020e+01  4.7000e+01  2.7900e+01  1.1742e+02 -2.5300e+00]\n",
      " [ 6.8830e+01  2.2220e+01  5.0090e+01  4.6610e+01  1.0599e+02 -3.5300e+00]\n",
      " [ 4.2020e+01 -6.5500e+00  6.7900e+01  4.8580e+01  1.1159e+02  2.7340e+01]\n",
      " [ 7.2340e+01  1.6420e+01  5.9870e+01  5.5920e+01  7.0080e+01  1.2070e+01]\n",
      " [ 5.0070e+01  9.1200e+00  3.2170e+01  4.0950e+01  9.9710e+01  2.6770e+01]\n",
      " [ 4.7660e+01  1.3280e+01  3.6680e+01  3.4380e+01  9.8250e+01  6.2700e+00]\n",
      " [ 5.7290e+01  1.5150e+01  6.4000e+01  4.2140e+01  1.1674e+02  3.0340e+01]\n",
      " [ 4.1730e+01  1.2250e+01  3.0120e+01  2.9480e+01  1.1659e+02 -1.2400e+00]\n",
      " [ 3.7900e+01  4.4800e+00  2.4710e+01  3.3420e+01  1.5785e+02  3.3610e+01]\n",
      " [ 7.7110e+01  3.0470e+01  6.9480e+01  4.6640e+01  1.1215e+02  7.0760e+01]\n",
      " [ 6.7260e+01  7.1900e+00  5.1700e+01  6.0070e+01  9.7800e+01  4.2140e+01]\n",
      " [ 4.6860e+01  1.5350e+01  3.8000e+01  3.1500e+01  1.1625e+02  1.6600e+00]\n",
      " [ 8.4970e+01  3.3020e+01  6.0860e+01  5.1950e+01  1.2566e+02  7.4330e+01]\n",
      " [ 6.6800e+01  1.4550e+01  7.2080e+01  5.2250e+01  8.2460e+01  4.1690e+01]\n",
      " [ 7.7120e+01  3.0350e+01  7.7480e+01  4.6770e+01  1.1061e+02  8.2090e+01]\n",
      " [ 6.1410e+01  2.5380e+01  3.9100e+01  3.6030e+01  1.0340e+02  2.1840e+01]\n",
      " [ 7.6330e+01  4.2400e+01  5.7200e+01  3.3930e+01  1.2427e+02  5.0130e+01]\n",
      " [ 6.0750e+01  1.5750e+01  4.3200e+01  4.5000e+01  1.1305e+02  3.1690e+01]\n",
      " [ 8.5000e+01  2.9610e+01  8.3350e+01  5.5390e+01  1.2691e+02  7.1320e+01]\n",
      " [ 3.1280e+01  3.1400e+00  3.2560e+01  2.8130e+01  1.2901e+02  3.6200e+00]\n",
      " [ 8.6750e+01  3.6040e+01  6.9220e+01  5.0710e+01  1.3941e+02  1.1086e+02]\n",
      " [ 6.3900e+01  1.3710e+01  6.2120e+01  5.0190e+01  1.1413e+02  4.1420e+01]\n",
      " [ 8.6470e+01  4.0300e+01  6.1140e+01  4.6170e+01  9.7400e+01  5.5750e+01]\n",
      " [ 6.7030e+01  1.3280e+01  6.6150e+01  5.3750e+01  1.0072e+02  3.3990e+01]\n",
      " [ 6.9560e+01  1.5400e+01  7.4440e+01  5.4160e+01  1.0507e+02  2.9700e+01]\n",
      " [ 4.0250e+01  1.3920e+01  2.5120e+01  2.6330e+01  1.3033e+02  2.2300e+00]\n",
      " [ 7.4720e+01  1.9760e+01  8.2740e+01  5.4960e+01  1.0936e+02  3.3310e+01]\n",
      " [ 4.4530e+01  9.4300e+00  5.2000e+01  3.5100e+01  1.3471e+02  2.9110e+01]\n",
      " [ 7.2080e+01  1.8950e+01  5.1000e+01  5.3130e+01  1.1421e+02  1.0100e+00]\n",
      " [ 4.6440e+01  8.4000e+00  2.9040e+01  3.8050e+01  1.1548e+02  2.0500e+00]\n",
      " [ 5.7300e+01  2.4190e+01  4.7000e+01  3.3110e+01  1.1681e+02  5.7700e+00]\n",
      " [ 6.3170e+01  6.3300e+00  6.3000e+01  5.6840e+01  1.1064e+02  4.2610e+01]\n",
      " [ 4.9710e+01  9.6500e+00  2.8320e+01  4.0060e+01  1.0817e+02  7.9200e+00]\n",
      " [ 5.6670e+01  1.3460e+01  4.3770e+01  4.3210e+01  9.3690e+01  2.1110e+01]\n",
      " [ 7.0680e+01  2.1700e+01  5.9180e+01  4.8970e+01  1.0301e+02  2.7810e+01]\n",
      " [ 5.4120e+01  2.6650e+01  3.5330e+01  2.7470e+01  1.2145e+02  1.5700e+00]\n",
      " [ 4.6390e+01  1.1080e+01  3.2140e+01  3.5310e+01  9.8770e+01  6.3900e+00]\n",
      " [ 6.7410e+01  1.7440e+01  6.0140e+01  4.9970e+01  1.1112e+02  3.3160e+01]\n",
      " [ 4.3920e+01  1.4180e+01  3.7830e+01  2.9740e+01  1.3446e+02  6.4500e+00]\n",
      " [ 7.4010e+01  2.1120e+01  5.7380e+01  5.2880e+01  1.2021e+02  7.4560e+01]\n",
      " [ 5.0210e+01  2.9760e+01  3.6100e+01  2.0450e+01  1.2829e+02  5.7400e+00]\n",
      " [ 6.9300e+01  2.4650e+01  4.4310e+01  4.4640e+01  1.0187e+02  1.1210e+01]\n",
      " [ 6.5010e+01  2.7600e+01  5.0950e+01  3.7410e+01  1.1658e+02  7.0200e+00]\n",
      " [ 4.4910e+01  1.0220e+01  4.4630e+01  3.4700e+01  1.3008e+02  3.7360e+01]\n",
      " [ 3.1230e+01  1.7720e+01  1.5500e+01  1.3520e+01  1.2006e+02  5.0000e-01]\n",
      " [ 4.8110e+01  1.4930e+01  3.5560e+01  3.3180e+01  1.2406e+02  7.9500e+00]\n",
      " [ 5.3850e+01  1.9230e+01  3.2780e+01  3.4620e+01  1.2167e+02  5.3300e+00]\n",
      " [ 4.4320e+01  1.2540e+01  3.6100e+01  3.1780e+01  1.2412e+02  5.4200e+00]\n",
      " [ 7.9480e+01  2.6730e+01  7.0650e+01  5.2740e+01  1.1859e+02  6.1700e+01]\n",
      " [ 7.4430e+01  4.1560e+01  2.7700e+01  3.2880e+01  1.0795e+02  5.0000e+00]\n",
      " [ 7.4720e+01  1.4320e+01  3.2500e+01  6.0400e+01  1.0718e+02  3.7020e+01]\n",
      " [ 7.7690e+01  2.1380e+01  6.4430e+01  5.6310e+01  1.1482e+02  2.6930e+01]\n",
      " [ 9.5480e+01  4.6550e+01  5.9000e+01  4.8930e+01  9.6680e+01  7.7280e+01]\n",
      " [ 6.9780e+01  1.3780e+01  5.8000e+01  5.6000e+01  1.1893e+02  1.7910e+01]\n",
      " [ 8.5680e+01  3.8650e+01  8.2680e+01  4.7030e+01  1.2084e+02  6.1960e+01]\n",
      " [ 6.7510e+01  3.3280e+01  9.6280e+01  3.4240e+01  1.4560e+02  8.8300e+01]\n",
      " [ 5.6030e+01  1.6300e+01  6.2280e+01  3.9730e+01  1.1402e+02 -2.3300e+00]\n",
      " [ 1.2983e+02  8.4000e+00  4.8380e+01  1.2143e+02  1.0769e+02  4.1854e+02]\n",
      " [ 8.5100e+01  2.1070e+01  9.1730e+01  6.4030e+01  1.0906e+02  3.8030e+01]\n",
      " [ 7.6310e+01  4.1930e+01  9.3280e+01  3.4380e+01  1.3227e+02  1.0122e+02]\n",
      " [ 8.1110e+01  2.0690e+01  6.0690e+01  6.0420e+01  9.4020e+01  4.0510e+01]\n",
      " [ 6.9760e+01  1.9280e+01  4.8500e+01  5.0480e+01  9.6490e+01  5.1170e+01]\n",
      " [ 5.8520e+01  1.3920e+01  4.1470e+01  4.4600e+01  1.1551e+02  3.0390e+01]\n",
      " [ 9.4170e+01  1.5380e+01  6.7710e+01  7.8790e+01  1.1489e+02  5.3260e+01]\n",
      " [ 1.1592e+02  3.7520e+01  7.6800e+01  7.8410e+01  1.0470e+02  8.1200e+01]\n",
      " [ 3.5700e+01  1.9440e+01  2.0700e+01  1.6260e+01  1.3754e+02 -2.6000e-01]\n",
      " [ 6.8720e+01  4.9430e+01  6.8060e+01  1.9290e+01  1.2502e+02  5.4690e+01]\n",
      " [ 8.0990e+01  3.6840e+01  8.6960e+01  4.4140e+01  1.4109e+02  8.5870e+01]\n",
      " [ 3.9060e+01  1.0060e+01  2.5020e+01  2.9000e+01  1.1441e+02  4.5600e+00]\n",
      " [ 5.7520e+01  3.3650e+01  5.0910e+01  2.3880e+01  1.4098e+02  1.4875e+02]\n",
      " [ 9.6660e+01  1.9460e+01  9.0210e+01  7.7200e+01  1.2067e+02  6.4080e+01]\n",
      " [ 6.4810e+01  1.5170e+01  5.8840e+01  4.9640e+01  1.1168e+02  2.1410e+01]\n",
      " [ 7.2560e+01  1.7390e+01  5.2000e+01  5.5180e+01  1.1919e+02  3.2110e+01]\n",
      " [ 5.5290e+01  2.0440e+01  3.4000e+01  3.4850e+01  1.1588e+02  3.5600e+00]\n",
      " [ 4.1770e+01  1.7900e+01  2.0030e+01  2.3870e+01  1.1836e+02  2.0600e+00]\n",
      " [ 5.9790e+01  1.7880e+01  5.9210e+01  4.1910e+01  1.1932e+02  2.2120e+01]\n",
      " [ 8.5290e+01  1.8280e+01  1.0074e+02  6.7010e+01  1.1066e+02  5.8880e+01]\n",
      " [ 8.7680e+01  2.0370e+01  9.3820e+01  6.7310e+01  1.2094e+02  7.6730e+01]\n",
      " [ 3.6130e+01  2.2760e+01  2.9000e+01  1.3370e+01  1.1558e+02 -3.2400e+00]\n",
      " [ 6.0420e+01  5.2700e+00  5.9810e+01  5.5150e+01  1.0903e+02  3.0270e+01]\n",
      " [ 7.9250e+01  2.3940e+01  4.0800e+01  5.5300e+01  9.8620e+01  3.6710e+01]\n",
      " [ 6.0040e+01  1.4310e+01  5.8040e+01  4.5730e+01  1.0513e+02  3.0410e+01]\n",
      " [ 4.7740e+01  1.2090e+01  3.9000e+01  3.5660e+01  1.1751e+02  2.1680e+01]\n",
      " [ 6.4620e+01  1.5230e+01  6.7630e+01  4.9400e+01  9.0300e+01  3.1330e+01]\n",
      " [ 7.9940e+01  1.8770e+01  6.3310e+01  6.1160e+01  1.1479e+02  3.8540e+01]\n",
      " [ 8.0110e+01  3.3940e+01  8.5100e+01  4.6170e+01  1.2559e+02  1.0029e+02]\n",
      " [ 6.9630e+01  2.1120e+01  5.2770e+01  4.8500e+01  1.1680e+02  5.4820e+01]\n",
      " [ 5.8830e+01  3.7580e+01  1.2574e+02  2.1250e+01  1.3563e+02  1.1731e+02]\n",
      " [ 4.5370e+01  1.0760e+01  2.9040e+01  3.4610e+01  1.1727e+02 -1.0680e+01]\n",
      " [ 5.8600e+01 -2.6000e-01  5.1500e+01  5.8860e+01  1.0204e+02  2.8060e+01]\n",
      " [ 5.6540e+01  1.4380e+01  4.4990e+01  4.2160e+01  1.0172e+02  2.5770e+01]\n",
      " [ 4.5440e+01  9.9100e+00  4.5000e+01  3.5540e+01  1.6307e+02  2.0320e+01]\n",
      " [ 7.8400e+01  1.4040e+01  7.9690e+01  6.4360e+01  1.0473e+02  1.2390e+01]\n",
      " [ 8.0070e+01  4.8070e+01  5.2400e+01  3.2010e+01  1.1071e+02  6.7730e+01]\n",
      " [ 8.9500e+01  4.8900e+01  7.2000e+01  4.0600e+01  1.3463e+02  1.1835e+02]\n",
      " [ 6.0630e+01  2.0600e+01  6.4540e+01  4.0030e+01  1.1723e+02  1.0486e+02]\n",
      " [ 8.5350e+01  1.5840e+01  7.1670e+01  6.9510e+01  1.2442e+02  7.6020e+01]\n",
      " [ 8.1100e+01  2.4790e+01  7.7890e+01  5.6310e+01  1.5184e+02  6.5210e+01]\n",
      " [ 4.8920e+01  1.9960e+01  4.0260e+01  2.8950e+01  1.1932e+02  8.0300e+00]\n",
      " [ 5.4740e+01  1.2100e+01  4.1000e+01  4.2650e+01  1.1764e+02  4.0380e+01]\n",
      " [ 4.3200e+01  1.9660e+01  3.5000e+01  2.3540e+01  1.2485e+02 -2.9200e+00]\n",
      " [ 6.6290e+01  2.6330e+01  4.7500e+01  3.9960e+01  1.2122e+02 -8.0000e-01]\n",
      " [ 6.5010e+01  9.8400e+00  5.7740e+01  5.5180e+01  9.4740e+01  4.9700e+01]\n",
      " [ 5.2420e+01  1.9010e+01  3.5870e+01  3.3410e+01  1.1656e+02  1.6900e+00]\n",
      " [ 4.1170e+01  1.7320e+01  3.3470e+01  2.3850e+01  1.1638e+02 -9.5700e+00]\n",
      " [ 7.7240e+01  1.6740e+01  4.9780e+01  6.0500e+01  1.1069e+02  3.9790e+01]\n",
      " [ 6.6880e+01  2.4890e+01  4.9280e+01  4.1990e+01  1.1348e+02 -2.0100e+00]\n",
      " [ 8.1060e+01  2.0800e+01  9.1780e+01  6.0260e+01  1.2543e+02  3.8180e+01]\n",
      " [ 5.3940e+01  9.3100e+00  4.3100e+01  4.4640e+01  1.2440e+02  2.5080e+01]\n",
      " [ 6.3400e+01  1.4120e+01  4.8140e+01  4.9290e+01  1.1192e+02  3.1780e+01]\n",
      " [ 7.3640e+01  9.7100e+00  6.3000e+01  6.3920e+01  9.8730e+01  2.6980e+01]\n",
      " [ 4.4940e+01  1.7440e+01  2.7780e+01  2.7490e+01  1.1798e+02  5.5700e+00]\n",
      " [ 3.8660e+01  1.2990e+01  4.0000e+01  2.5680e+01  1.2491e+02  2.7000e+00]\n",
      " [ 9.0510e+01  2.8270e+01  6.9810e+01  6.2240e+01  1.0089e+02  5.8820e+01]\n",
      " [ 8.1080e+01  2.1260e+01  7.8770e+01  5.9830e+01  9.0070e+01  4.9160e+01]\n",
      " [ 6.5760e+01  9.8300e+00  5.0820e+01  5.5920e+01  1.0439e+02  3.9310e+01]\n",
      " [ 8.0650e+01  2.6340e+01  6.0900e+01  5.4310e+01  1.2010e+02  5.2470e+01]\n",
      " [ 8.4590e+01  3.0360e+01  6.5480e+01  5.4220e+01  1.0801e+02  2.5120e+01]\n",
      " [ 7.4850e+01  1.3910e+01  6.2690e+01  6.0950e+01  1.1521e+02  3.3170e+01]\n",
      " [ 7.0480e+01  1.2490e+01  6.2420e+01  5.7990e+01  1.1419e+02  5.6900e+01]\n",
      " [ 5.5510e+01  2.0100e+01  4.4000e+01  3.5420e+01  1.2265e+02  3.4550e+01]\n",
      " [ 2.6150e+01  1.0760e+01  1.4000e+01  1.5390e+01  1.2520e+02 -1.0090e+01]\n",
      " [ 5.6990e+01  6.8700e+00  5.7010e+01  5.0120e+01  1.0998e+02  3.6810e+01]\n",
      " [ 5.6560e+01  8.9600e+00  5.2580e+01  4.7600e+01  9.8780e+01  5.0700e+01]\n",
      " [ 3.5490e+01  1.1700e+01  1.5590e+01  2.3790e+01  1.0694e+02 -3.4600e+00]\n",
      " [ 7.2640e+01  1.8930e+01  6.8000e+01  5.3710e+01  1.1696e+02  2.5380e+01]\n",
      " [ 7.1190e+01  2.3900e+01  4.3700e+01  4.7290e+01  1.1986e+02  2.7280e+01]\n",
      " [ 8.6900e+01  3.2930e+01  4.7790e+01  5.3970e+01  1.3508e+02  1.0172e+02]\n",
      " [ 5.6610e+01  1.6800e+01  4.2000e+01  3.9810e+01  1.2729e+02  2.4020e+01]\n",
      " [ 4.9710e+01  1.3040e+01  3.1330e+01  3.6670e+01  1.0865e+02 -7.8300e+00]\n",
      " [ 6.3770e+01  1.2760e+01  6.5360e+01  5.1010e+01  8.9820e+01  5.6000e+01]\n",
      " [ 7.0250e+01  1.0340e+01  7.6370e+01  5.9910e+01  1.1924e+02  3.2670e+01]\n",
      " [ 6.5540e+01  2.4160e+01  4.5780e+01  4.1380e+01  1.3644e+02  1.6380e+01]\n",
      " [ 4.0560e+01  1.7980e+01  3.4000e+01  2.2580e+01  1.2105e+02 -1.5400e+00]\n",
      " [ 5.0830e+01  9.0600e+00  5.6300e+01  4.1760e+01  7.9000e+01  2.3040e+01]]\n"
     ]
    }
   ],
   "source": [
    "VertebralVar_train_AB = VertebralVar_train[VertebralClas_train==\"AB\"]\n",
    "VertebralVar_train_NO = VertebralVar_train[VertebralClas_train==\"NO\"]\n",
    "print(VertebralVar_train_AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "n_AB = VertebralVar_train_AB.shape[0]\n",
    "n_NO = VertebralVar_train_NO.shape[0]\n",
    "print(n_AB)\n",
    "print(n_NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# ntot = Vertebral.shape[0]\n",
    "# shuffled_indices = np.random.permutation(ntot)\n",
    "# print(shuffled_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ntrain = shuffled_indices[:200]\n",
    "# ntest = shuffled_indices[200:]\n",
    "# ntrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VertebralVar_train,VertebralVar_test,VertebralClas_train, VertebralClas_test = train_test_split(VertebralVar,\n",
    "#                                                                                                 VertebralClas, \n",
    "#                                                                                                 train_size=ntrain.shape[0], random_state=0)\n",
    "# VertebralVar_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Discriminante Linéaire (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Implémenter le classifieur de l'analyse discriminante linéaire en l'appliquant sur les données. Vous pourrez utiliser les fonctions [`empirical_covariance`](http://scikit-learn.org/stable/modules/generated/sklearn.covariance.EmpiricalCovariance.html#sklearn.covariance.EmpiricalCovariance) de  la librairie5 [`sklearn.covariance`](http://scikit-learn.org/stable/modules/covariance.html) et la fonction [`multivariate_normal`](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.multivariate_normal.html) de la librairie \n",
    "[`scipy.stats`](https://docs.scipy.org/doc/scipy/reference/stats.html). Ajuster le classifieur sur l'échantillon d'apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'abord on calcule le centre et la matrice de covariance pour chacun des deux groupes  :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import empirical_covariance\n",
    "Cov_AB = empirical_covariance(VertebralVar_train_AB)\n",
    "Cov_NO = empirical_covariance(VertebralVar_train_NO)\n",
    "mean_AB = VertebralVar_train_AB.mean(axis=0)\n",
    "mean_NO = VertebralVar_train_NO.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 64.28807407  19.54296296  53.86251852  44.74555556 115.26918519\n",
      "  36.82696296]\n",
      "[ 52.83353846  13.01323077  44.48969231  39.81984615 122.94692308\n",
      "   2.05215385]\n"
     ]
    }
   ],
   "source": [
    "print(mean_AB)\n",
    "print(mean_NO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis on calcule la matrice de covariance intra :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 258.23006193   77.26587814  193.30591263  180.9598814   -47.75392602\n",
      "   351.46951707]\n",
      " [  77.26587814   84.53376818   56.75127579   -7.26833095   14.55822686\n",
      "    89.08490231]\n",
      " [ 193.30591263   56.75127579  317.17205969  136.55449554  -15.45547742\n",
      "   277.48800238]\n",
      " [ 180.9598814    -7.26833095  136.55449554  188.22438116  -62.3074406\n",
      "   262.390221  ]\n",
      " [ -47.75392602   14.55822686  -15.45547742  -62.3074406   162.22365997\n",
      "    41.90537798]\n",
      " [ 351.46951707   89.08490231  277.48800238  262.390221     41.90537798\n",
      "  1404.17856577]]\n"
     ]
    }
   ],
   "source": [
    "Intra_Cov = (n_AB * Cov_AB + n_NO * Cov_NO) / (n_AB + n_NO)\n",
    "print(Intra_Cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant calculer le score sur chaque groupe pour chaque element des données de test  :\n",
    "<center>\n",
    "[Vraisemblance du groupe]  * [proba a priori ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6.049766206118149e-06, 5.221931243850173e-06],\n",
       " [4.843275403936803e-05, 5.6702274810849085e-05],\n",
       " [1.9817486689167988e-06, 4.5272598230228606e-08],\n",
       " [3.925778665287586e-06, 3.5902944146402e-07],\n",
       " [2.186403590189722e-07, 4.365144933236242e-09],\n",
       " [5.039711257700715e-05, 2.6712126703061875e-06],\n",
       " [2.4581812235795424e-05, 1.258279463157992e-05],\n",
       " [4.4480341736296455e-05, 2.120690725826617e-05],\n",
       " [3.045534948057192e-05, 4.574462716112964e-06],\n",
       " [2.99250345939698e-05, 7.285904365056379e-07],\n",
       " [3.7446410809425316e-05, 2.0355187338259323e-05],\n",
       " [0.00012918278687227416, 3.568692257117976e-05],\n",
       " [2.724312120379971e-05, 1.1370043278801602e-06],\n",
       " [4.1723227830175604e-05, 2.627054531696764e-05],\n",
       " [5.8240651651899696e-05, 4.8745501715579857e-05],\n",
       " [1.2418603231274043e-05, 1.0498418692751563e-05],\n",
       " [1.0337085789689213e-05, 3.403371465357874e-05],\n",
       " [4.280959588443644e-06, 5.028467514955806e-06],\n",
       " [1.7675977682070975e-05, 3.5861454502979453e-06],\n",
       " [1.8207316613703397e-06, 1.2896662185392155e-05],\n",
       " [6.0728876832649936e-05, 4.406026421574734e-06],\n",
       " [8.46795407068632e-05, 3.6702275921324785e-05],\n",
       " [4.0894977523893955e-05, 8.394034857862696e-06],\n",
       " [1.149296195457876e-05, 8.874413865999752e-07],\n",
       " [4.685226081592807e-06, 6.10267867394811e-06],\n",
       " [6.396948973364608e-05, 1.5164601640120372e-05],\n",
       " [1.0730412039315633e-08, 1.6009386639301975e-10],\n",
       " [5.2594916179686816e-05, 4.727182721343567e-05],\n",
       " [6.775465997714955e-05, 3.833210133706199e-05],\n",
       " [3.45556687382682e-06, 9.719331391428896e-07],\n",
       " [6.604674484476174e-06, 2.5425993620008817e-07],\n",
       " [2.4657308858280667e-06, 4.196508272838849e-08],\n",
       " [2.800161031027965e-07, 3.819536261127114e-06],\n",
       " [1.596041335810216e-05, 4.775260264780259e-06],\n",
       " [3.739854175883969e-06, 2.774305682621502e-07],\n",
       " [4.9843154648263576e-11, 3.589808677963044e-13],\n",
       " [2.3233202769520178e-05, 6.654836757206379e-06],\n",
       " [3.449141210008865e-05, 5.090150444384703e-05],\n",
       " [1.005853597500975e-05, 3.8708860334721677e-07],\n",
       " [2.9246510220582422e-05, 3.869992941228754e-05],\n",
       " [5.9026904251910175e-06, 1.0027395915778256e-06],\n",
       " [9.78868702622009e-07, 5.533613894062131e-08],\n",
       " [4.5807605413060865e-06, 3.4602348410424554e-06],\n",
       " [6.3861757917884605e-06, 6.1551834489116294e-06],\n",
       " [4.99970835979549e-05, 5.371189266132631e-05],\n",
       " [2.1381207932867282e-07, 1.3375241930416463e-08],\n",
       " [2.5537323489355785e-05, 9.479246461803416e-07],\n",
       " [3.234880655111612e-05, 6.924739821723958e-06],\n",
       " [1.0780230396409142e-06, 9.355828584675958e-06],\n",
       " [9.481186888911511e-06, 2.0681860818007898e-06],\n",
       " [4.669990406995752e-05, 2.3341120399652456e-05],\n",
       " [2.0862546380937044e-05, 9.26316719651135e-06],\n",
       " [1.7736773536917303e-06, 5.585328533667493e-07],\n",
       " [8.483944411618479e-05, 6.438585860775689e-05],\n",
       " [4.385523439623789e-07, 2.1437672109917282e-07],\n",
       " [3.707688150387322e-06, 7.731475297135939e-08],\n",
       " [1.153047338041189e-05, 1.4237628703440568e-05],\n",
       " [3.719182946598935e-06, 1.1064097090123869e-06],\n",
       " [1.3041979220262885e-06, 8.860557298706338e-06],\n",
       " [2.4457172611727564e-05, 5.0730060505104586e-06],\n",
       " [8.252743413625057e-05, 9.012455969665612e-06],\n",
       " [3.832804659159634e-05, 1.0909438490703951e-06],\n",
       " [6.650552319825066e-05, 4.1887256001109214e-05],\n",
       " [5.9409309722250464e-05, 1.4962327145524153e-05],\n",
       " [1.0539229939240654e-06, 2.1997027690651295e-07],\n",
       " [6.917442253141232e-06, 6.674291737782518e-07],\n",
       " [4.744453894500571e-05, 2.910915287309349e-05],\n",
       " [5.3281798939089365e-05, 1.4118567384010978e-05],\n",
       " [3.4041673215560245e-06, 2.587384861289665e-07],\n",
       " [5.87778382485132e-07, 1.2240690615368998e-08],\n",
       " [2.7069938196026667e-05, 3.587635871116212e-05],\n",
       " [5.537212877763383e-07, 3.053199904691507e-08],\n",
       " [2.016297964689602e-06, 9.783147269434417e-07],\n",
       " [1.7435471752683245e-05, 2.2824002561410014e-06],\n",
       " [2.1071082291817887e-06, 8.662114412264911e-07],\n",
       " [9.88131703388089e-06, 2.8467381618881776e-05],\n",
       " [4.647070448462778e-06, 1.4867040232449013e-05],\n",
       " [6.599085759418047e-05, 1.4409898343308666e-05],\n",
       " [8.432781591068554e-06, 1.1763084882677068e-06],\n",
       " [0.00011131574164741061, 3.2825386979430005e-05],\n",
       " [1.5145122803641286e-06, 2.8393205987070496e-07],\n",
       " [6.90035819709718e-05, 5.1978187069439355e-05],\n",
       " [9.563987963022901e-06, 2.3382519035081836e-06],\n",
       " [1.3964253132025486e-05, 8.361267805375981e-06],\n",
       " [1.6544176192807776e-05, 6.888354173119237e-06],\n",
       " [1.648115608067279e-05, 4.526724274866106e-05],\n",
       " [2.9587481970372578e-05, 6.851351231899597e-06],\n",
       " [2.092849845100798e-05, 3.458302511910768e-06],\n",
       " [3.3912330974642002e-06, 1.529474562011581e-07],\n",
       " [0.00011204912275183829, 5.47450414505458e-05],\n",
       " [8.75674214563333e-06, 1.937120821620704e-06],\n",
       " [5.219589517426625e-05, 1.4180377853558792e-05],\n",
       " [1.906829555313189e-05, 8.19769654776711e-07],\n",
       " [1.1108883059751181e-05, 2.7511144545958646e-05],\n",
       " [7.590528868157092e-06, 9.103767813865682e-06],\n",
       " [7.535955146300139e-06, 1.4985644088847448e-06],\n",
       " [1.432525149318719e-05, 3.2448347820121194e-06],\n",
       " [2.5086217488781175e-06, 1.0372470595675181e-06],\n",
       " [2.0525894286922553e-06, 5.363727372996451e-06],\n",
       " [3.859821593944676e-06, 3.2592456838483372e-06],\n",
       " [1.3420524065754068e-06, 6.698605743326169e-06],\n",
       " [1.1775424910908984e-05, 1.8393360607588022e-05],\n",
       " [1.033610724368024e-05, 2.5492884604069853e-06],\n",
       " [4.565353982711485e-06, 2.631960463943033e-07],\n",
       " [9.160597055803218e-06, 1.942226552488038e-06],\n",
       " [3.223711478527204e-06, 1.3416651663190949e-05],\n",
       " [1.7477875047977653e-05, 2.7075648742980635e-05],\n",
       " [1.2318310121521873e-05, 2.879444243993669e-06],\n",
       " [9.564705606961941e-05, 5.152571098131393e-05]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_LDA_test = [   [ \n",
    "n_AB * multivariate_normal.pdf(x,mean=mean_AB, cov=Intra_Cov), # densité d'une gausienne multivariée, de moyenne mean_AB\n",
    "    # et de matrice de var-covar Intra_Cov\n",
    "n_NO * multivariate_normal.pdf(x,mean=mean_NO, cov=Intra_Cov),]  for x in VertebralVar_test] \n",
    "\n",
    "# en mettant la même matrice de variance covariance, on fait du LDA, et non du QDA\n",
    "score_LDA_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "et on applique la règle de decision finale sur les données de test : max a posteriori :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_LDA_test = [l.index(max(l)) for l in score_LDA_test]\n",
    "pred_LDA_test\n",
    "# VertebralClas_test  # pour comparaison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Evaluer les performances de la méthode sur l'échantillon test. Vous pourrez utiliser la fonction [`confusion_matrix`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix) de la librairie [`sklearn.metrics`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98648649, 0.01351351],\n",
       "       [0.37142857, 0.62857143]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "vraie_classe_test = 1 * (VertebralClas_test == \"NO\") \n",
    "cnf_matrix_LDA_test = confusion_matrix(vraie_classe_test,pred_LDA_test)\n",
    "cnf_matrix_LDA_test.astype('float') / cnf_matrix_LDA_test.sum(axis=1).reshape(-1,1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Vérifier que l'évaluation de la méthode sur les données d'apprentissage donne un résulat sensiblement plus optimiste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91851852, 0.08148148],\n",
       "       [0.4       , 0.6       ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_LDA_train =  [   [ \n",
    "n_AB * multivariate_normal.pdf(x,mean=mean_AB, cov=Intra_Cov), # densité d'une gausienne multivariée, de moyenne mean_AB\n",
    "    # et de matrice de var-covar Intra_Cov\n",
    "n_NO * multivariate_normal.pdf(x,mean=mean_NO, cov=Intra_Cov),]  for x in VertebralVar_train] \n",
    "pred_LDA_train = [l.index(max(l)) for l in score_LDA_train]\n",
    "vraie_classe_train = 1 * (VertebralClas_train == \"NO\") \n",
    "cnf_matrix_LDA_train =  confusion_matrix(vraie_classe_train,pred_LDA_train)\n",
    "cnf_matrix_LDA_train.astype('float') / cnf_matrix_LDA_train.sum(axis=1).reshape(-1,1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe bien sûr une fonction scikit-learn pour la méthode LDA : voir [ici](http://scikit-learn.org/0.16/modules/generated/sklearn.lda.LDA.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Discriminante Quadratique (QDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Implémenter de même pour la méthode de l'analyse Discriminante Quadratique (QDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.86486486, 0.13513514],\n",
       "       [0.14285714, 0.85714286]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_QDA_test =  [   [ \n",
    "n_AB * multivariate_normal.pdf(x,mean=mean_AB, cov=Cov_AB), # densité d'une gausienne multivariée, de moyenne mean_AB\n",
    "    # et de matrice de var-covar Intra_Cov\n",
    "n_NO * multivariate_normal.pdf(x,mean=mean_NO, cov=Cov_NO),]  for x in VertebralVar_test] \n",
    "pred_QDA_test = [l.index(max(l)) for l in score_QDA_test]\n",
    "cnf_matrix_QDA_test = confusion_matrix(vraie_classe_test,pred_QDA_test)\n",
    "cnf_matrix_QDA_test.astype('float') / cnf_matrix_QDA_test.sum(axis=1).reshape(-1,1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe bien sûr une fonction scikit-learn pour la méthode QDA : voir [ici](http://scikit-learn.org/0.16/modules/generated/sklearn.qda.QDA.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Implémenter le classifieur naif bayesien et évaluer les performances de la méthode sur l'échantillon test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Calcul des variances de chaque variable pour chacun des deux groupes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 76.15  21.94  82.96  54.21 123.93  10.43]\n",
      " [ 95.38  24.82  95.16  70.56  89.31  57.66]\n",
      " [ 92.03  35.39  77.42  56.63 115.72  58.06]\n",
      " [ 43.72   9.81  52.    33.91  88.43  40.88]\n",
      " [ 85.58  30.46  78.23  55.12 114.87  68.38]\n",
      " [ 78.49  22.18  60.    56.31 118.53  27.38]\n",
      " [ 43.58  16.51  47.    27.07 109.27   8.99]\n",
      " [ 75.65  19.34  64.15  56.31  95.9   69.55]\n",
      " [ 70.95  20.16  62.86  50.79 116.18  32.52]\n",
      " [ 83.4   34.31  78.42  49.09 110.47  49.67]\n",
      " [ 43.35   7.47  28.07  35.88 112.78   5.75]\n",
      " [ 45.54  13.07  30.3   32.47 117.98  -4.99]\n",
      " [ 48.03   3.97  58.34  44.06 125.35  35.  ]\n",
      " [ 82.41  29.28  77.05  53.13 117.04  62.77]\n",
      " [ 63.83  20.36  54.55  43.47 112.31  -0.62]\n",
      " [ 81.66  28.75  58.23  52.91 114.77  30.61]\n",
      " [ 89.68  32.7   83.13  56.98 129.96  92.03]\n",
      " [ 53.57  20.46  33.1   33.11 110.97   7.04]\n",
      " [ 70.22  39.82  68.12  30.4  148.53 145.38]\n",
      " [ 68.61  15.08  63.01  53.53 123.43  39.5 ]\n",
      " [ 88.62  29.09  47.56  59.53 121.76  51.81]\n",
      " [ 48.26  16.42  36.33  31.84  94.88  28.34]\n",
      " [ 85.64  42.69  78.75  42.95 105.14  42.89]\n",
      " [ 86.04  38.75  47.87  47.29 122.09  61.99]\n",
      " [118.14  38.45  50.84  79.7   81.02  74.04]\n",
      " [ 83.7   20.27  77.11  63.43 125.48  69.28]\n",
      " [ 88.02  39.84  81.77  48.18 116.6   56.77]\n",
      " [ 30.15  11.92  34.    18.23 112.68  11.46]\n",
      " [ 83.93  41.29  62.    42.65 115.01  26.59]\n",
      " [ 38.7   13.44  31.    25.25 123.16   1.43]\n",
      " [ 36.69   5.01  41.95  31.68  84.24   0.66]\n",
      " [ 72.05  24.7   79.87  47.35 107.17  56.43]\n",
      " [ 44.22   1.51  46.11  42.71 108.63  42.81]\n",
      " [ 63.36  20.02  67.5   43.34 131.    37.56]\n",
      " [ 52.2   17.21  78.09  34.99 136.97  54.94]\n",
      " [ 53.43  15.86  37.17  37.57 120.57   5.99]\n",
      " [ 74.38  32.05  78.77  42.32 143.56  56.13]\n",
      " [ 75.44  31.54  89.6   43.9  106.83  54.97]\n",
      " [ 31.48   7.83  24.28  23.66 113.83   4.39]\n",
      " [ 59.6   32.    46.56  27.6  119.33   1.47]\n",
      " [ 63.07  24.41  54.    38.66 106.42  15.78]\n",
      " [ 77.41  29.4   63.23  48.01 118.45  93.56]\n",
      " [ 43.79  13.53  42.69  30.26 125.    13.29]\n",
      " [ 48.33  22.23  36.18  26.1  117.38   6.48]\n",
      " [ 77.66  22.43  93.89  55.22 123.06  61.21]\n",
      " [ 58.1   14.84  79.65  43.26 113.59  50.24]\n",
      " [ 75.3   16.67  61.3   58.63 118.88  31.58]\n",
      " [ 80.43  17.    66.54  63.43 116.44  57.78]\n",
      " [ 48.06   5.69  57.06  42.37  95.44  32.84]\n",
      " [ 71.    37.52  84.54  33.49 125.16  67.77]\n",
      " [ 74.47  33.28  66.94  41.19 146.47 124.98]\n",
      " [ 71.24   5.27  86.    65.97 110.7   38.26]\n",
      " [ 83.88  23.08  87.14  60.8  124.65  80.56]\n",
      " [ 72.22  23.08  91.    49.14 137.74  56.8 ]\n",
      " [ 70.4   13.47  61.2   56.93 102.34  25.54]\n",
      " [ 78.43  33.43  76.28  45.   138.55  77.16]\n",
      " [ 50.82  15.4   42.53  35.42 112.19  10.87]\n",
      " [ 41.19   5.79  42.87  35.39 103.35  27.66]\n",
      " [ 54.92  21.06  42.2   33.86 125.21   2.43]\n",
      " [ 41.35  16.58  30.71  24.78 113.27  -4.5 ]\n",
      " [ 74.09  18.82  76.03  55.27 128.41  73.39]\n",
      " [ 44.55  21.93  26.79  22.62 111.07   2.65]\n",
      " [ 64.27  12.51  68.7   51.77  95.25  39.41]\n",
      " [ 55.84  28.85  47.69  27.   123.31   2.81]\n",
      " [ 81.75  20.12  70.56  61.63 119.43  55.51]\n",
      " [ 80.82  19.24  61.64  61.58  89.47  44.17]\n",
      " [ 44.25   1.1   38.    43.15  98.27  23.91]\n",
      " [ 91.47  24.51  84.62  66.96 117.31  52.62]\n",
      " [ 55.08  -3.76  56.    58.84 109.92  31.77]\n",
      " [ 32.09   6.99  36.    25.1  132.26   6.41]\n",
      " [ 49.78   6.47  53.    43.32 110.86  25.34]\n",
      " [ 58.78   7.67  53.34  51.12  98.5   51.58]\n",
      " [ 57.04   0.35  49.2   56.69 103.05  52.17]\n",
      " [ 65.67  10.54  56.49  55.12 109.16  53.93]]\n"
     ]
    }
   ],
   "source": [
    "VertebralVar_test_AB = VertebralVar_test[VertebralClas_test==\"AB\"]\n",
    "VertebralVar_test_NO = VertebralVar_test[VertebralClas_test==\"NO\"]\n",
    "print(VertebralVar_test_AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 64.28807407  19.54296296  53.86251852  44.74555556 115.26918519\n",
      "  36.82696296]\n"
     ]
    }
   ],
   "source": [
    "mean_AB_test = VertebralVar_test_AB.mean(axis=0)\n",
    "mean_NO_test = VertebralVar_test_NO.mean(axis=0)\n",
    "print(mean_AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1601.587013254438\n"
     ]
    }
   ],
   "source": [
    "# variances estimées coord par coord pour AB (sur le train) :\n",
    "var_AB = np.var(VertebralVar_train_AB)\n",
    "# variances estimées coord par coord pour NO (sur le train) :\n",
    "var_NO = np.var(VertebralVar_train_NO)\n",
    "print(var_NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[170.61558902,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  0.        ,  43.35198187,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  0.        ,   0.        , 160.16678144,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  0.        ,   0.        ,   0.        ,  97.48687844,\n",
       "          0.        ,   0.        ],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "         78.0323413 ,   0.        ],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,  32.44572767]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on forme les matrices de covariance (matrices diagonales car indep) :\n",
    "Cov_NB_AB =  np.diag(np.diag(Cov_AB))\n",
    "Cov_NB_NO =  np.diag(np.diag(Cov_NO))\n",
    "Cov_NB_NO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul du \"score\" sur chaque groupe pour chaque element des données test : \n",
    "<center>\n",
    " [Vraisemblance du groupe]  * [proba a priori ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_NB_test = [   [ \n",
    "n_AB * multivariate_normal.pdf(x,mean=mean_AB_test, cov=Cov_NB_AB), # densité d'une gausienne multivariée, de moyenne mean_AB\n",
    "    # et de matrice de var-covar Intra_Cov\n",
    "n_NO * multivariate_normal.pdf(x,mean=mean_NO_test, cov=Cov_NB_NO),]  for x in VertebralVar_test] \n",
    "pred_NB_test = [l.index(max(l)) for l in score_NB_test] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77027027, 0.22972973],\n",
       "       [0.08571429, 0.91428571]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix_NB_test = confusion_matrix(vraie_classe_test,pred_NB_test)\n",
    "cnf_matrix_NB_test.astype('float') / cnf_matrix_NB_test.sum(axis=1).reshape(-1,1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    ">  Il existe bien sûr une fonction scikit-learn  pour la méthode Naive Bayes : voir [ici](http://scikit-learn.org/stable/modules/naive_bayes.html). Vérifier que votre prédicteur donne la même réponse de cette fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109,) (109,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mix of label input types (string and number)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-516d00be4ee0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVertebralVar_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvraie_classe_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mcnf_matrix_NB_test_bis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvraie_classe_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mcnf_matrix_NB_test_bis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mcnf_matrix_NB_test_bis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;31m# Check that we don't mix string type with number type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mys_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mix of label input types (string and number)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Mix of label input types (string and number)"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(VertebralVar_test,VertebralClas_test)\n",
    "y_pred=gnb.predict(VertebralVar_test)\n",
    "print(y.shape, vraie_classe_test.shape)\n",
    "cnf_matrix_NB_test_bis = confusion_matrix(vraie_classe_test,y_pred)\n",
    "cnf_matrix_NB_test_bis.astype('float') / cnf_matrix_NB_test_bis.sum(axis=1).reshape(-1,1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifieur par plus proches voisins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est préférable d'utiliser la structure de données de type [k-d tree](https://en.wikipedia.org/wiki/K-d_tree) pour effectuer des requêtes de plus proches voisins dans un nuage de points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Contruction du k-d tree pour les données train (pour la métrique euclidienne) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "from scipy import spatial\n",
    "tree =  spatial.KDTree(VertebralVar_train, leafsize=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Rechercher les 10 plus proches voisins dans les données d'apprentissage du premier point des données de test et afficher les classes de ces voisins observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  45 146  14 154  51  68  19  39  58]]\n"
     ]
    }
   ],
   "source": [
    "indices_voisins =  tree.query(VertebralVar_train[:1,],k=10)[1]\n",
    "print(indices_voisins) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'NO', 'NO', 'NO', 'NO'],\n",
      "      dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "classes_voisins = [VertebralClas_train[i,] for i in indices_voisins]\n",
    "print(classes_voisins)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le classifieur par plus proches vosins, la prediction est la classe majoritaire des k plus proches voisins.\n",
    "\n",
    "> Donner la prédiction pour le premier point de test par vote majoritaire sur ses 10 plus proches voisins "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pour le premier point, le vote majoritaire est AB\n"
     ]
    }
   ],
   "source": [
    "def vote(classes_voisins):\n",
    "    n_AB_kd=0\n",
    "    n_NO_kd=0\n",
    "    for i in range(len(classes_voisins)):\n",
    "        if classes_voisins[0][i]==\"AB\" : n_AB_kd += 1\n",
    "        else : n_NO_kd += 1\n",
    "    if n_AB_kd > n_NO_kd:\n",
    "        return(\"AB\")\n",
    "    else:\n",
    "        return(\"NO\")\n",
    "\n",
    "print(\"Pour le premier point, le vote majoritaire est\", vote(classes_voisins),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Donner la prediction du classifieur ppv pour toutes les données de test. Evaluer la qualité du classifieur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AB'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pred_classes_voisins(tree,var,clas,i,k):\n",
    "    indices_voisins = tree.query(var[(i-1):i], k)[1]\n",
    "    classes_voisins=clas[indices_voisins]\n",
    "    return classes_voisins\n",
    "\n",
    "tree_test=KDTree(VertebralVar_test, leaf_size=2)\n",
    "vote(pred_classes_voisins(tree_test, VertebralVar_test, VertebralClas_test, 9, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_class = ### CHOISIR  ####  #nombre de plus proche voisins utilisés\n",
    "pred_kNN_test =  ### TO DO ####\n",
    "cnf_matrix_kNN =### TO DO ####\n",
    "cnf_matrix_kNN.astype('float') / cnf_matrix_kNN.sum(axis=1).reshape(-1,1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe bien sûr une fonction scikit-learn pour le classifieur plus proche voisin, voir [ici](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
